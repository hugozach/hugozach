# 秒速爬取100张原创插画

**本文仅供学习交流**

### 摘要

在本文中，我们将介绍如何利用 Python 程序快速爬取100张原创插画的图片。我们将通过获取数据和下载图片两个步骤来实现这个目标。请注意，本文中的代码仅供学习交流使用。

### 1. 获取数据

在开始之前，我们需要获取插画数据。这里有两种情况：

**情况1：通过 Chrome 调试定位获取接口**

如果我们能够使用 Chrome 浏览器进行调试，并定位到获取插画数据的接口，那么我们可以直接通过该接口获取数据。具体步骤如下：

1. 打开 Chrome 浏览器并访问包含插画数据的网页。
2. 打开开发者工具（可以通过右键菜单或快捷键打开）。
3. 切换到 Network 面板，并清空所有已有的请求。
4. 浏览网页时，观察 Network 面板中的请求，找到包含插画数据的接口。
5. 点击该请求，查看请求详情，在 Headers 或 Preview 面板中找到响应数据。
6. 将获取到的数据保存下来，用于后续的处理。

**情况2：通过服务器端渲染（SSR）获取数据**

如果网页是通过服务器端渲染（SSR）加载的，我们无法直接定位到接口，需要使用 Selenium 等工具来获取页面代码，并通过正则表达式等方式解析数据。具体步骤如下：

1. 使用 Selenium 打开浏览器，并访问包含插画数据的网页。
2. 获取页面代码，可以通过 Selenium 提供的相关方法来获取。
3. 使用正则表达式等方式解析页面代码，提取出插画数据。
4. 将获取到的数据保存下来，用于后续的处理。
![image-20230710110929493](https://c18e-1257416358.cos.accelerate.myqcloud.com/image-20230710110929493.png)
![image-20230710111357125](https://c18e-1257416358.cos.accelerate.myqcloud.com/image-20230710111357125.png)
![image-20230710111549381](https://c18e-1257416358.cos.accelerate.myqcloud.com/image-20230710111549381.png)
![image-20230710111845101](https://c18e-1257416358.cos.accelerate.myqcloud.com/image-20230710111845101.png)















### 2. 下载图片

获取到插画数据后，我们可以根据数据中的图片地址进行下载。具体步骤如下：

1. 创建一个线程池，用于并发下载图片。
2. 遍历插画数据，提取每张插画的图片地址。
3. 对于每个图片地址，创建一个下载任务，使用多线程的方式进行下载。
4. 在下载任务中，发送 HTTP 请求获取图片数据，并将数据保存到本地文件。
5. 等待所有下载任务完成，确保所有图片都已经下载完毕。

### 3. 编写代码
```python
import json
import httpx
from concurrent.futures import ThreadPoolExecutor
```

- 导入所需的模块：`json` 用于处理 JSON 数据，`httpx` 用于发送 HTTP 请求，`ThreadPoolExecutor` 用于创建线程池。

```python
def get_data():
    url = "https://api.huaban.com/discovery/illustration"
    params = {"limit": "100", "max": "5588131249"}
    headers = {
        # 头部信息，包含请求的cookie、user-agent等
    }
    response = httpx.get(url, headers=headers, params=params)
    if response.status_code == 200:
        return response.json().get("pins", [])
    else:
        return []
```

- 定义 `get_data` 函数，用于获取数据。
- 指定 API 的 URL 和参数。
- 设置请求的头部信息。
- 发送 GET 请求，获取响应。
- 检查响应状态码是否为 200，如果是，则解析响应的 JSON 数据并返回其中的 `"pins"` 字段的值，否则返回空列表。

```python
def download_images(url, filename):
    with httpx.stream("GET", url) as response:
        with open(filename, "wb") as f:
            for chunk in response.iter_bytes():
                f.write(chunk)
    print(f"{filename} 下载完成！")
```

- 定义 `download_images` 函数，用于下载图片。
- 使用 `httpx.stream` 发送 GET 请求，获取响应流。
- 打开文件，将响应数据写入文件。
- 打印下载完成的提示信息。

```python
if __name__ == "__main__":
    data = get_data()
    print(f"共有{len(data)}个文件开始下载")

    executor = ThreadPoolExecutor(max_workers=500)

    for item in data:
        key = item.get("file", {}).get("key")
        if not key:
            continue

        url = f"https://gd-hbimg.huaban.com/{key}_fw480webp"
        filename = f"imgs/{key}.webp"
        executor.submit(download_images, url, filename)

    executor.shutdown(wait=True)
```

- 在 `__name__ == "__main__"` 的条件下执行以下代码块。
- 调用 `get_data` 函数，获取插画数据，并打印下载文件数量的信息。
- 创建线程池执行器 `executor`，最大工作线程数为 500。
- 遍历数据中的每个元素，提取图片的关键信息。
- 构建图片的 URL 和保存的文件名。
- 使用线程池执行器提交下载任务，将图片的 URL 和文件名传递给 `download_images` 函数进行下载。
- 等待所有下载任务完成后关闭线程池。

完整代码
```python
import json
import httpx
from concurrent.futures import ThreadPoolExecutor

def get_data():
    url = "https://api.huaban.com/discovery/illustration"

    params = {"limit": "100", "max": "5588131249"}

    headers = {
        "cookie": "user_device_id=1b8a9e842cda4dfc83392d3950ac7c0e; user_device_id_timestamp=1688952997879; Hm_lvt_d4a0e7c3cd16eb58a65472f40e7ee543=1688952998; Hm_up_d4a0e7c3cd16eb58a65472f40e7ee543=%7B%22version%22%3A%7B%22value%22%3A%222.0.0%22%2C%22scope%22%3A1%7D%2C%22has_plugin%22%3A%7B%22value%22%3A%220%22%2C%22scope%22%3A1%7D%7D; _gid=GA1.2.1601091990.1688952998; aliyungf_tc=1c0de47c75c109b66f5d448fdbd463121af41b30c6c0edbba3a10e752a3c6ddb; sid=s%3ALrlT63DV6NFuC9Kl9kOdUsFEwWcAGl0v.kUB0XzR0tHJNIbNLPlgt2OLp3FQRzZiQqek%2FgbWRCnk; _ga_50RYEM7F09=GS1.1.1688952998.1.1.1688955222.0.0.0; Hm_lpvt_d4a0e7c3cd16eb58a65472f40e7ee543=1688955224; _ga=GA1.2.332528593.1688952998; _gat_UA-135559536-2=1",
        "user-agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
        "authority": "api.huaban.com",
        "accept": "application/json, text/plain, */*",
        "accept-language": "zh-CN,zh;q=0.9,en;q=0.8,de;q=0.7",
        "cache-control": "no-cache",
        "origin": "https://huaban.com",
        "pragma": "no-cache",
        "referer": "https://huaban.com/discovery/illustration?sort=1",
        "sec-ch-ua": f'"Not.A/Brand";v="8", "Chromium";v="114", "Google Chrome";v="114"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"macOS"',
        "sec-fetch-dest": "empty",
        "sec-fetch-mode": "cors",
        "sec-fetch-site": "same-site"
    }

    response = httpx.get(url, headers=headers, params=params)
    if response.status_code == 200:
        return response.json().get("pins", [])
    else:
        return []

def download_images(url, filename):
    with httpx.stream("GET", url) as response:
        with open(filename, "wb") as f:
            for chunk in response.iter_bytes():
                f.write(chunk)
    print(f"{filename} 下载完成！")

if __name__ == "__main__":
    data = get_data()
    print(f"共有{len(data)}个文件开始下载")

    executor = ThreadPoolExecutor(max_workers=500)

    for item in data:
        key = item.get("file", {}).get("key")
        if not key:
            continue

        url = f"https://gd-hbimg.huaban.com/{key}_fw480webp"
        filename = f"imgs/{key}.webp"
        executor.submit(download_images, url, filename)

    executor.shutdown(wait=True)
```

通过以上代码，我们可以将获取数据和下载图片分别封装成两个函数。使用 `httpx` 库发送 HTTP 请求，并使用线程池来提高并发处理能力。首先通过 `get_data` 函数获取插画数据，然后遍历数据列表，提取每个图片的关键信息，拼接出图片的下载地址，最后通过 `download_images` 函数下载图片并保存到本地。

请注意，本示例仅供学习交流，请遵守法律法规和网站规则，不要滥用爬虫技术。
